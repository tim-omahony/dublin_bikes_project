{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pymysql'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-224d29461bdb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpymysql\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pymysql'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "from sqlalchemy import create_engine\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pymysql\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pickle\n",
    "import matplotlib.dates as mdates\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "USER = \"ciara\"\n",
    "PASSWORD = \"Ciara123\"\n",
    "PORT = \"3306\"\n",
    "DB = \"dbbikes\"\n",
    "URI = \"dbbikes.cvr6gofoxmkp.us-east-2.rds.amazonaws.com\"\n",
    "engine = create_engine(\"mysql+pymysql://{}:{}@{}:{}/{}\".format(USER, PASSWORD, URI, PORT, DB), echo=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = f\"\"\"\n",
    "SELECT id, number, updated_on, available_bikes, available_bike_stands\n",
    "FROM dbbikes_info\n",
    "WHERE updated_on is not null and updated_on >= '2021-03-24 19:25:16' and number != 507\n",
    "GROUP BY id, day(updated_on)\n",
    "ORDER by id desc, updated_on desc;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_df = pd.read_sql_query(sql, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_df['updated_on'] = bike_df['updated_on'].astype('datetime64[ns]')\n",
    "bike_df['updated_on'] = pd.to_datetime(bike_df['updated_on'])\n",
    "bike_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = f\"\"\"\n",
    "SELECT * FROM weather;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df = pd.read_sql_query(sql, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# category    \n",
    "weather_df['description'] = weather_df['description'].astype('category')    \n",
    "\n",
    "# datetime   \n",
    "weather_df['last_update'] = weather_df['last_update'].astype('datetime64[ns]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_df.sort_values('updated_on', inplace=True)\n",
    "weather_df.sort_values('last_update', inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge_asof(bike_df, weather_df, left_on='updated_on', right_on='last_update')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['last_update'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['id_y'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['id_x'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of duplicate (excluding first) rows in the table is: ', df.duplicated().sum())\n",
    "\n",
    "print('Number of duplicate rows (including first) in the table is:', df[df.duplicated(keep=False)].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(keep='last')\n",
    "print('Duplicate remaining rows:', df[df.duplicated(keep='last')].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hourly'] = df['updated_on'].dt.hour\n",
    "hourly_dummies = pd.get_dummies(df['hourly'], prefix='hour')\n",
    "df = pd.concat([df, hourly_dummies], axis=1)\n",
    "hour_dummies = list(hourly_dummies)\n",
    "df = df.drop(['hourly'], axis=1)\n",
    "\n",
    "df['weekday'] = df['updated_on'].dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head(10))\n",
    "print(df.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = list(sorted(df.number.unique()))\n",
    "weekdays = list(sorted(df.weekday.unique()))\n",
    "models = {}\n",
    "\n",
    "i = 0\n",
    "\n",
    "for station in stations:\n",
    "    models[station] = {}\n",
    "    for weekday in weekdays:\n",
    "        df1 = df[(df['number'] == station) & (df['weekday'] == weekday)]\n",
    "        y = pd.DataFrame(df1, columns=['available_bikes', 'temp'])\n",
    "        X = pd.DataFrame(df1, columns=['hour_0', 'hour_1', 'hour_2', 'hour_3', 'hour_4',\n",
    "       'hour_5', 'hour_6', 'hour_7', 'hour_8', 'hour_9', 'hour_10', 'hour_11',\n",
    "       'hour_12', 'hour_13', 'hour_14', 'hour_15', 'hour_16', 'hour_17',\n",
    "       'hour_18', 'hour_19', 'hour_20', 'hour_21', 'hour_22', 'hour_23'])\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "        models[station][weekday] = LinearRegression().fit(X_train, y_train)\n",
    "        model = LinearRegression().fit(X_train, y_train)\n",
    "        \n",
    "        train_predictions = model.predict(X_train)\n",
    "        # print('Train predictions for station ', station, \": \", train_predictions)\n",
    "\n",
    "        test_predictions = model.predict(X_test)\n",
    "        # print('Test predictions for station ', station, \": \", test_predictions)\n",
    "\n",
    "        \n",
    "        r2 = metrics.r2_score(y_test, test_predictions)\n",
    "\n",
    "        # how well does the model behave compared to a chosen r2 ? \n",
    "        if r2 > 0.5:             \n",
    "            i +=1\n",
    "\n",
    "print('Percentage of models that have outperformed r2 = 0.5:', (i /109) * 100)  # there are 109 stations\n",
    "# print(i)\n",
    "# print(len(stations))\n",
    "\n",
    "# with open('model.pkl', 'wb') as handle:\n",
    "#     pickle.dump(models, handle, protocol = pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
